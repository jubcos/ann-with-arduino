{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MMFH\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3778 - loss: 1.5549 - val_accuracy: 0.6464 - val_loss: 1.3925\n",
      "Epoch 2/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6636 - loss: 1.3600 - val_accuracy: 0.7459 - val_loss: 1.2215\n",
      "Epoch 3/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7435 - loss: 1.1805 - val_accuracy: 0.8232 - val_loss: 1.0520\n",
      "Epoch 4/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.9971 - val_accuracy: 0.9171 - val_loss: 0.8801\n",
      "Epoch 5/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8912 - loss: 0.8514 - val_accuracy: 0.9448 - val_loss: 0.7248\n",
      "Epoch 6/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9335 - loss: 0.6845 - val_accuracy: 0.9503 - val_loss: 0.5904\n",
      "Epoch 7/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9392 - loss: 0.5737 - val_accuracy: 0.9724 - val_loss: 0.4742\n",
      "Epoch 8/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9515 - loss: 0.4779 - val_accuracy: 0.9669 - val_loss: 0.3958\n",
      "Epoch 9/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9528 - loss: 0.3848 - val_accuracy: 0.9779 - val_loss: 0.3377\n",
      "Epoch 10/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9561 - loss: 0.3530 - val_accuracy: 0.9779 - val_loss: 0.2873\n",
      "Epoch 11/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9568 - loss: 0.2929 - val_accuracy: 0.9834 - val_loss: 0.2519\n",
      "Epoch 12/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.2578 - val_accuracy: 0.9779 - val_loss: 0.2247\n",
      "Epoch 13/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.2296 - val_accuracy: 0.9834 - val_loss: 0.1994\n",
      "Epoch 14/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.2112 - val_accuracy: 0.9779 - val_loss: 0.1807\n",
      "Epoch 15/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.1797 - val_accuracy: 0.9779 - val_loss: 0.1634\n",
      "Epoch 16/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.1707 - val_accuracy: 0.9779 - val_loss: 0.1525\n",
      "Epoch 17/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.1400 - val_accuracy: 0.9779 - val_loss: 0.1400\n",
      "Epoch 18/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.1381 - val_accuracy: 0.9779 - val_loss: 0.1312\n",
      "Epoch 19/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.1303 - val_accuracy: 0.9779 - val_loss: 0.1221\n",
      "Epoch 20/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9849 - loss: 0.1180 - val_accuracy: 0.9779 - val_loss: 0.1160\n",
      "Epoch 21/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9873 - loss: 0.1077 - val_accuracy: 0.9834 - val_loss: 0.1077\n",
      "Epoch 22/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0916 - val_accuracy: 0.9779 - val_loss: 0.1040\n",
      "Epoch 23/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.1157 - val_accuracy: 0.9834 - val_loss: 0.0976\n",
      "Epoch 24/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0876 - val_accuracy: 0.9779 - val_loss: 0.0947\n",
      "Epoch 25/25\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9865 - loss: 0.0869 - val_accuracy: 0.9834 - val_loss: 0.0896\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Load digits dataset and filter for digits 0, 1, 2, 3, 4, 5, 6\n",
    "digits = load_digits()\n",
    "data = digits.data / 16.0  # Normalize data\n",
    "labels = digits.target\n",
    "\n",
    "# Filter out digits 0, 1, 2, 3, 4\n",
    "mask = np.isin(labels, [0, 1, 2, 3, 4])\n",
    "data = data[mask]\n",
    "labels = labels[mask]\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "# Split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)\n",
    "\n",
    "# Build the neural network\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(64,)),\n",
    "    Dense(24, activation='relu'),  # 24 neurons in the hidden layer\n",
    "    Dense(5, activation='softmax')  # Output layer with 7 neurons for digits 0 to 6\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=25, validation_data=(x_test, y_test))\n",
    "\n",
    "# Save the weights and biases\n",
    "weights = model.get_weights()\n",
    "np.savez('mnist_weights_64_24_10.npz', *weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the weights and biases\n",
    "weights_and_biases = np.load('mnist_weights_64_24_10.npz')\n",
    "\n",
    "weights_input_hidden = weights_and_biases['arr_0']\n",
    "bias_hidden = weights_and_biases['arr_1']\n",
    "weights_hidden_output = weights_and_biases['arr_2']\n",
    "bias_output = weights_and_biases['arr_3']\n",
    "\n",
    "def format_array(array, array_name):\n",
    "    if array.ndim == 1:\n",
    "        array_str = \", \".join(f\"{v:.6f}\" for v in array)\n",
    "        formatted_array = f\"float {array_name}[] = {{{array_str}}};\\n\"\n",
    "    else:\n",
    "        array_str = \",\\n\".join(\n",
    "            \"  {\" + \", \".join(f\"{v:.6f}\" for v in row) + \"}\" for row in array\n",
    "        )\n",
    "        formatted_array = f\"float {array_name}[][] = {{\\n{array_str}\\n}};\\n\"\n",
    "    return formatted_array\n",
    "\n",
    "weights_input_hidden = format_array(weights_input_hidden, \"weights_input_hidden[input_neurons][hidden_neurons]\")\n",
    "bias_hidden = format_array(bias_hidden, \"bias_hidden[hidden_neurons]\")\n",
    "weights_hidden_output = format_array(weights_hidden_output, \"weights_hidden_output[hidden_neurons][output_neurons]\")\n",
    "formatted_bias_output = format_array(bias_output, \"bias_output[output_neurons]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float weights_input_hidden[input_neurons][hidden_neurons][][] = {\n",
      "  {-0.091072, -0.154139, -0.037374, 0.071164, -0.101689, -0.224732, -0.237812, 0.198153, 0.116446, 0.177320, 0.217389, -0.225780, -0.141065, -0.170832, -0.055156, 0.037201, -0.114473, 0.189741, -0.019169, 0.145487, -0.010692, 0.103027, 0.121493, 0.000488},\n",
      "  {-0.344511, 0.197282, 0.080317, -0.013895, 0.044339, -0.013208, -0.170689, -0.207137, 0.165638, -0.166017, 0.353229, -0.357412, -0.190910, 0.095150, 0.052835, -0.338326, -0.263936, 0.095639, -0.045629, -0.185887, -0.109214, -0.218366, -0.261129, 0.145171},\n",
      "  {-0.220110, 0.172230, 0.097444, 0.327734, 0.208655, -0.044943, -0.020362, -0.124958, -0.141076, -0.020917, 0.093391, -0.317260, 0.174827, 0.191100, -0.193419, -0.297724, -0.162698, 0.088377, 0.184977, -0.018190, -0.058679, 0.174488, 0.127995, 0.219810},\n",
      "  {0.223185, 0.225408, 0.201138, -0.184929, 0.219814, 0.246853, 0.185884, -0.234734, -0.256854, -0.109116, 0.074588, -0.329600, -0.110762, 0.128507, -0.129108, -0.113894, 0.176631, 0.140976, 0.093268, 0.106261, -0.024594, -0.085981, -0.149337, 0.067528},\n",
      "  {-0.016798, -0.049116, 0.111211, 0.194169, 0.068776, 0.278838, -0.044805, 0.068316, 0.238973, -0.239178, -0.200191, 0.050076, -0.273992, -0.079505, 0.042564, -0.154482, 0.242854, -0.231951, -0.101800, -0.053048, -0.032507, 0.014747, -0.035133, 0.176165},\n",
      "  {0.359778, -0.206389, -0.104998, 0.047769, 0.479589, -0.315116, 0.111872, -0.014777, -0.057440, 0.252070, 0.221412, 0.051872, 0.176245, -0.258488, -0.085333, -0.338212, 0.333445, -0.116573, -0.147157, -0.095819, 0.330559, 0.108380, 0.166917, 0.177499},\n",
      "  {0.331742, 0.054825, -0.230090, -0.002466, 0.387449, -0.088017, -0.153315, 0.023474, -0.252461, 0.295552, -0.243664, 0.220049, -0.083827, -0.325579, -0.119190, -0.132339, 0.087166, 0.113798, -0.141679, 0.006180, 0.026014, -0.187508, 0.209137, 0.022396},\n",
      "  {-0.018641, -0.158187, -0.214398, 0.264327, -0.218450, 0.136654, -0.104559, -0.038085, -0.091741, 0.115243, 0.074410, -0.115294, -0.242038, 0.326901, 0.241400, 0.001728, 0.204099, 0.117958, 0.085434, -0.061887, -0.157800, 0.066145, -0.177243, -0.135915},\n",
      "  {-0.255481, -0.165546, 0.061351, 0.059984, -0.160416, 0.287478, -0.067797, -0.147390, 0.165776, 0.174401, -0.030370, -0.114255, 0.170824, -0.105945, 0.188943, 0.237160, -0.185983, 0.058979, -0.222605, 0.207129, 0.013358, 0.156464, 0.157614, 0.038429},\n",
      "  {-0.000832, -0.093346, -0.176011, 0.360739, 0.293133, 0.164798, -0.281816, 0.132219, 0.072218, -0.289494, 0.203293, -0.399575, 0.102595, 0.097028, -0.046418, -0.402649, 0.073437, -0.064218, 0.204704, -0.169820, -0.438749, -0.111990, 0.113412, 0.447429},\n",
      "  {-0.095152, -0.154181, 0.250588, 0.324797, 0.098694, 0.237908, -0.214544, 0.037664, -0.116696, 0.031621, 0.305777, -0.368995, 0.097741, 0.185001, 0.104221, -0.385703, 0.165739, -0.025707, -0.087339, 0.067014, -0.167878, -0.212143, -0.071509, 0.354984},\n",
      "  {-0.072510, -0.016925, 0.001710, -0.005466, -0.068514, 0.230141, 0.138726, 0.041949, 0.037694, 0.274476, -0.066586, -0.004850, 0.198627, 0.069098, 0.190381, 0.255342, -0.145019, -0.161158, -0.014302, 0.102624, -0.035965, -0.132065, 0.011968, 0.247312},\n",
      "  {-0.072291, 0.084014, 0.248133, -0.003155, 0.369420, 0.250420, 0.074244, -0.273333, -0.354973, 0.033219, 0.409907, 0.078382, 0.011454, 0.086610, -0.063030, -0.077705, 0.002385, 0.163751, -0.058466, -0.178997, -0.059797, 0.110204, -0.030425, 0.044874},\n",
      "  {0.279081, -0.122674, -0.027360, -0.313304, 0.492516, -0.258031, -0.169997, 0.099605, -0.208721, 0.080520, 0.139064, -0.418314, -0.153502, 0.197944, -0.289345, 0.053013, 0.215818, 0.237752, 0.115327, 0.216810, -0.027385, -0.157579, 0.226373, 0.361891},\n",
      "  {0.091270, -0.130601, 0.077759, -0.080725, 0.213086, -0.157778, -0.118980, -0.239744, 0.060668, 0.002486, -0.135775, -0.002131, -0.090144, 0.219366, -0.110148, -0.028013, -0.001103, -0.082729, -0.249453, -0.257890, -0.014929, -0.273479, -0.285896, 0.054166},\n",
      "  {-0.273994, -0.147443, -0.031639, -0.053314, 0.154317, 0.268738, -0.087535, -0.041749, 0.117982, -0.025325, 0.156708, 0.252337, -0.168583, 0.092616, 0.250468, 0.240201, -0.067457, -0.145698, -0.071511, -0.218532, 0.062829, 0.096456, -0.191348, -0.251937},\n",
      "  {-0.295157, 0.257583, -0.111226, -0.188927, 0.244248, 0.035310, -0.177629, 0.078305, -0.102667, -0.011783, -0.145475, -0.021784, 0.095093, 0.063424, 0.179955, 0.087929, 0.113682, -0.142106, -0.150482, 0.154679, -0.022231, 0.218579, -0.129499, -0.096664},\n",
      "  {-0.179362, -0.213978, -0.000267, 0.064398, 0.262632, -0.028009, 0.070877, -0.000925, -0.263643, -0.088938, 0.296800, -0.038126, -0.135426, 0.076116, 0.011209, -0.062931, 0.095135, 0.110806, 0.204975, 0.109579, -0.074416, 0.163486, -0.186607, -0.036844},\n",
      "  {0.026944, 0.199222, 0.375289, 0.067582, -0.051831, 0.405727, -0.229705, 0.029344, 0.018380, 0.446441, 0.202136, 0.308668, 0.198238, 0.186031, 0.113704, 0.407599, 0.204259, -0.121795, 0.347111, -0.251878, -0.160222, 0.164710, -0.177780, -0.151060},\n",
      "  {0.279321, -0.126886, -0.147797, -0.202041, -0.347601, -0.306290, -0.052230, 0.149739, 0.163072, 0.120988, -0.030634, 0.493945, 0.103424, -0.225096, -0.098140, 0.247441, 0.157617, 0.134494, 0.287488, 0.029659, 0.351446, 0.119150, -0.210178, -0.115119},\n",
      "  {0.376746, 0.010926, -0.337811, -0.032504, 0.195278, -0.357168, 0.180379, -0.083227, -0.093421, -0.050735, 0.050239, 0.269188, -0.279514, -0.193775, -0.328957, 0.435868, 0.226997, 0.073911, 0.072860, 0.120565, 0.035930, -0.047115, -0.039753, 0.333056},\n",
      "  {-0.218191, -0.284658, 0.162431, -0.015853, -0.007621, 0.112992, 0.146968, -0.103134, 0.050261, -0.132005, 0.012752, -0.322266, -0.259550, 0.057616, -0.116869, 0.165472, 0.061334, -0.129253, 0.179682, -0.096555, -0.199417, -0.305639, -0.086255, 0.114609},\n",
      "  {0.009180, 0.159114, 0.326530, 0.194106, 0.052051, 0.104418, 0.061757, -0.257721, -0.022009, 0.011695, -0.253740, 0.008991, -0.141847, -0.040395, 0.308251, 0.262635, -0.189112, 0.071361, 0.218261, -0.125497, -0.076033, -0.177903, -0.156765, -0.139734},\n",
      "  {0.013521, -0.013610, -0.115175, 0.142967, -0.094870, 0.179726, -0.238785, 0.232586, 0.294836, -0.392265, 0.072757, 0.206256, -0.138211, 0.401518, -0.043588, 0.165814, -0.049816, 0.177012, -0.052747, 0.110194, 0.063104, 0.274708, 0.140521, -0.293476},\n",
      "  {-0.134117, -0.176708, 0.064833, 0.089593, 0.147798, -0.092880, 0.003062, -0.205019, 0.251265, -0.076258, -0.102934, 0.079759, -0.068761, 0.199380, -0.002189, -0.094829, 0.008851, 0.246102, 0.162238, 0.237819, 0.165083, -0.170982, 0.221847, -0.083990},\n",
      "  {0.254295, -0.260215, 0.283323, -0.206259, -0.083384, 0.124976, -0.152272, -0.157315, 0.052287, -0.004764, -0.042482, 0.418472, -0.255655, 0.211745, -0.017359, 0.145877, 0.270919, -0.198628, 0.216759, 0.097372, 0.056766, 0.070144, 0.114854, -0.084152},\n",
      "  {-0.030793, -0.226275, 0.334023, -0.353172, -0.033028, 0.097252, 0.053194, 0.008543, 0.100855, 0.473227, -0.218393, 0.403320, -0.197241, 0.347544, 0.437570, 0.107966, 0.087815, 0.149371, 0.418049, 0.051918, 0.332559, -0.143069, -0.089300, -0.065690},\n",
      "  {0.555353, -0.027339, -0.319356, -0.079056, -0.003897, -0.417277, 0.264825, 0.213379, -0.074086, 0.508624, 0.026821, 0.122627, 0.047861, 0.106949, -0.260929, 0.421826, 0.066748, -0.015830, -0.386069, -0.133506, 0.408290, -0.083652, 0.078058, -0.067976},\n",
      "  {0.104710, 0.148328, -0.044449, 0.087848, 0.495205, 0.050960, -0.056705, 0.105953, -0.231782, -0.269691, 0.157676, 0.313424, -0.237561, -0.234125, -0.167944, 0.273137, -0.068744, -0.125639, -0.033359, 0.177926, 0.020244, -0.246894, -0.228881, 0.309640},\n",
      "  {-0.254216, 0.203042, -0.084438, 0.200351, -0.177735, 0.231694, 0.096075, 0.025642, 0.150557, 0.184426, 0.187296, 0.060201, -0.102599, -0.036400, 0.176648, 0.181335, 0.137458, -0.226964, 0.255447, 0.206845, 0.036344, -0.219453, 0.220729, 0.002268},\n",
      "  {-0.123479, -0.253402, 0.140261, -0.056074, -0.213435, 0.051075, -0.174825, 0.024058, 0.152891, 0.122496, -0.009066, 0.264273, 0.165813, 0.296839, 0.276172, 0.301176, 0.229131, -0.187171, 0.475953, -0.137084, 0.173655, 0.169188, -0.229146, 0.064971},\n",
      "  {-0.007205, 0.178059, 0.108571, -0.100689, -0.117145, -0.154420, 0.149662, -0.087281, 0.285588, -0.109149, -0.059964, 0.269913, -0.068743, 0.353623, 0.009947, 0.238749, -0.063407, -0.154465, -0.006406, -0.024393, -0.145617, -0.034377, 0.171536, 0.000764},\n",
      "  {0.162748, -0.181404, -0.001199, 0.202110, -0.250522, -0.174598, -0.101405, -0.131728, -0.048270, -0.116573, 0.021639, 0.186209, -0.130615, 0.048564, -0.233984, 0.060843, -0.096719, -0.008116, -0.068946, 0.064886, -0.183286, -0.115381, -0.142519, 0.102987},\n",
      "  {-0.216367, 0.010317, 0.293301, 0.176309, -0.260376, 0.293946, 0.178486, -0.019930, 0.410968, 0.154589, -0.155762, 0.306080, -0.106753, 0.475832, 0.338352, 0.358134, 0.392001, -0.183723, 0.061852, -0.085276, -0.138305, 0.084601, -0.175898, -0.208571},\n",
      "  {0.192131, -0.203465, 0.185863, 0.058605, -0.429093, 0.161223, -0.202253, 0.178299, 0.098624, -0.038304, -0.278645, 0.271683, -0.109423, 0.527001, 0.234136, 0.118714, 0.284270, -0.051806, 0.183932, 0.235304, 0.061920, -0.203837, 0.127929, -0.380143},\n",
      "  {0.025597, -0.082477, -0.223036, 0.155008, -0.050479, -0.123761, -0.063584, -0.050421, -0.088746, -0.183837, 0.258744, 0.112266, -0.003595, -0.029274, -0.193967, 0.049431, -0.140161, -0.151500, -0.020032, -0.114133, 0.180559, 0.105287, 0.047986, 0.042550},\n",
      "  {0.086012, -0.174758, -0.451427, 0.111548, 0.311000, -0.122675, -0.051118, -0.111027, 0.258047, -0.150873, 0.058264, 0.352792, 0.005316, 0.206698, -0.101544, 0.398799, 0.125110, -0.112526, -0.128963, -0.218291, 0.398018, -0.074470, -0.246895, -0.092249},\n",
      "  {-0.059008, -0.181129, -0.287490, 0.169108, 0.299148, -0.167036, 0.128402, -0.085840, 0.387398, -0.017257, -0.377953, -0.099256, -0.111933, 0.154646, 0.195587, 0.330290, 0.471663, -0.248167, -0.394390, -0.224832, 0.007846, -0.085650, -0.162427, 0.147470},\n",
      "  {-0.012268, -0.055476, -0.010522, 0.032695, -0.106923, 0.058587, -0.173834, -0.085433, 0.099273, 0.044860, -0.534685, 0.124518, -0.135343, 0.522220, 0.172729, 0.114184, 0.455782, -0.170275, -0.169114, 0.133619, -0.124429, 0.158789, -0.039610, 0.351627},\n",
      "  {-0.260110, -0.130492, 0.154343, 0.145050, 0.069971, 0.101743, 0.063821, -0.217021, 0.016083, 0.238125, 0.059113, 0.191544, -0.233509, 0.152924, 0.188934, -0.031330, -0.171925, -0.028766, 0.165882, -0.022628, -0.053396, -0.105973, 0.100374, -0.014291},\n",
      "  {0.144067, 0.095691, -0.070880, -0.146937, -0.076586, 0.112642, 0.089484, 0.169903, -0.077210, -0.256438, -0.323410, -0.023039, -0.091426, -0.056582, 0.289172, 0.179116, -0.022832, 0.211319, 0.065253, 0.165418, 0.025572, 0.013227, 0.250032, -0.080796},\n",
      "  {-0.357939, -0.165639, -0.105406, 0.128829, -0.366087, 0.494990, -0.251378, 0.170158, 0.216457, -0.522185, -0.089563, 0.176742, -0.169206, 0.572997, 0.425405, 0.077192, -0.014206, -0.200820, 0.013916, -0.107954, -0.144934, 0.040044, -0.226007, 0.046714},\n",
      "  {-0.034857, -0.104216, 0.464965, 0.291703, -0.271004, 0.105317, -0.273644, 0.061882, 0.264376, 0.264301, 0.269080, 0.247507, -0.151915, -0.051319, 0.069253, 0.083352, 0.132188, -0.019942, 0.457169, -0.244866, -0.001894, -0.203176, 0.033937, 0.190238},\n",
      "  {-0.176020, 0.014869, -0.037712, 0.388581, 0.066604, 0.238508, 0.104474, -0.253697, 0.252792, -0.232534, 0.235357, 0.283247, 0.022237, -0.009636, 0.024849, 0.175608, -0.135326, -0.134383, 0.524038, -0.128564, 0.302052, -0.204603, -0.240155, -0.335421},\n",
      "  {0.183579, 0.155593, -0.280507, 0.213580, 0.158896, 0.242115, -0.262222, 0.101598, 0.161855, 0.039323, 0.163744, 0.247533, -0.093973, 0.257334, 0.283764, 0.049599, -0.177255, -0.208721, -0.249349, 0.032286, 0.479893, 0.083574, 0.014348, -0.423288},\n",
      "  {0.403062, 0.131051, -0.102336, 0.020218, 0.010676, 0.017259, -0.234052, -0.211454, 0.034671, 0.081422, -0.509116, -0.024710, -0.043525, 0.319254, 0.306827, -0.156120, 0.510826, 0.011789, -0.208923, -0.156419, -0.070490, 0.072815, 0.165008, 0.131652},\n",
      "  {-0.167122, -0.182254, 0.095655, -0.387681, 0.010269, -0.292990, 0.128540, -0.097479, -0.112607, -0.362485, -0.204689, 0.035540, 0.074268, 0.567745, 0.189032, -0.385385, 0.314732, 0.143982, -0.368731, -0.004229, -0.292334, -0.113480, -0.148372, 0.556824},\n",
      "  {-0.009354, -0.059688, 0.166983, 0.293807, -0.076887, 0.273744, 0.089837, 0.103495, 0.002135, -0.066258, 0.174688, -0.040981, 0.113639, -0.022039, -0.244050, -0.326183, 0.006371, -0.146797, 0.204870, 0.031834, -0.061289, -0.170203, -0.189898, 0.068793},\n",
      "  {0.042824, 0.171261, 0.163186, -0.028858, -0.263240, 0.168841, 0.010203, 0.014471, -0.017204, -0.191778, 0.043567, 0.249537, 0.012535, -0.277080, 0.221694, -0.171545, 0.109853, 0.185377, -0.051940, -0.138545, 0.178060, -0.114859, 0.007988, -0.199367},\n",
      "  {-0.316572, -0.132822, -0.049737, 0.106965, 0.006209, 0.075463, 0.159279, 0.000443, 0.227163, -0.089885, 0.369986, 0.095257, 0.000477, 0.094466, 0.194387, 0.143586, -0.327320, 0.171250, -0.251395, 0.175077, -0.124588, 0.191475, 0.022158, 0.298037},\n",
      "  {0.137804, -0.130664, 0.243129, 0.117082, 0.380062, 0.087542, 0.077714, 0.135065, -0.227983, 0.034269, -0.007904, 0.100570, -0.028520, 0.043227, 0.265757, -0.337022, -0.018312, -0.069444, 0.252026, -0.228132, -0.214805, 0.114937, 0.001587, 0.455670},\n",
      "  {-0.278829, 0.180156, 0.451546, -0.051282, -0.007528, 0.094032, 0.109682, -0.187267, 0.080974, -0.162725, 0.328945, 0.215867, 0.172265, -0.373749, -0.046745, 0.077305, -0.357719, -0.208225, 0.241440, -0.037574, 0.076280, 0.171003, -0.011393, -0.131603},\n",
      "  {0.221641, 0.088516, 0.034494, -0.060227, -0.042579, -0.115717, -0.116113, -0.161785, -0.072723, 0.230142, 0.166790, 0.154765, -0.018631, -0.206252, 0.085206, -0.176217, -0.144988, 0.049972, 0.206137, 0.034939, 0.113824, -0.056438, -0.032380, -0.116316},\n",
      "  {-0.160858, -0.268319, 0.059427, 0.131805, 0.339720, 0.006450, -0.265731, -0.042060, -0.254159, 0.219343, 0.268040, 0.006255, 0.176313, -0.165602, 0.104771, -0.439893, -0.056878, -0.135403, 0.361452, -0.177998, 0.164603, 0.001266, 0.038288, 0.355663},\n",
      "  {-0.192273, 0.097879, 0.053936, 0.328548, 0.470743, -0.128103, -0.075107, -0.004824, -0.076376, 0.105253, -0.040046, -0.361072, 0.111385, -0.236508, -0.354614, -0.323927, -0.226809, 0.168172, 0.104318, 0.235761, -0.189853, 0.152712, 0.075667, 0.410245},\n",
      "  {0.271564, 0.105665, 0.314057, 0.135469, 0.179689, -0.242132, -0.217449, -0.139405, 0.065116, 0.448434, 0.092100, 0.309267, -0.205332, -0.141942, -0.090782, 0.181480, -0.311737, -0.212219, 0.340935, 0.100096, 0.363583, 0.227768, -0.005657, -0.337405},\n",
      "  {-0.121949, -0.225160, 0.050204, 0.228256, 0.047131, 0.135668, -0.102008, -0.168911, 0.289777, 0.141040, -0.159843, -0.246534, 0.248792, 0.055740, -0.112594, 0.129517, -0.082098, 0.238296, 0.067793, 0.217771, -0.305058, 0.179054, 0.205091, 0.371565},\n",
      "  {-0.382850, -0.129038, 0.162587, 0.167878, 0.030798, 0.124377, -0.154852, 0.238470, -0.132077, -0.181961, -0.002894, -0.175414, -0.269619, 0.013164, -0.068630, -0.181022, 0.139766, 0.015558, 0.030968, -0.256477, -0.428024, -0.181138, -0.064078, 0.060018},\n",
      "  {-0.080525, -0.005552, 0.221137, 0.362730, 0.087547, 0.167294, -0.132843, -0.109893, -0.324052, -0.245232, 0.352248, -0.199145, -0.036826, -0.090106, -0.085155, -0.097298, 0.174859, 0.069041, -0.157013, -0.049051, 0.087993, 0.146832, 0.169996, 0.568212},\n",
      "  {-0.079823, -0.219156, 0.058048, 0.003832, 0.139642, -0.186045, -0.160594, -0.117866, -0.292164, -0.266398, 0.092473, -0.183087, -0.143156, 0.032072, 0.204784, -0.115957, 0.086995, -0.103865, -0.046762, 0.090487, 0.049864, 0.186695, 0.039333, 0.354620},\n",
      "  {0.163636, -0.200640, 0.058763, 0.023191, 0.414833, 0.003049, 0.219474, 0.071214, 0.201039, -0.151479, 0.155038, -0.138693, -0.302389, 0.198716, -0.118773, 0.134933, -0.067568, -0.092921, 0.026969, -0.181466, 0.056686, 0.128564, -0.004667, 0.109422},\n",
      "  {0.001137, 0.040428, -0.035329, -0.000510, 0.410665, 0.254444, 0.031796, 0.101192, -0.111416, 0.390630, 0.469197, 0.306756, -0.097234, -0.102019, -0.077498, -0.204279, -0.124685, 0.146478, -0.044481, -0.258998, 0.317138, 0.007290, -0.089649, 0.016625},\n",
      "  {0.035148, -0.135993, 0.340940, 0.125835, 0.230705, 0.163172, 0.128322, -0.044244, -0.108936, 0.240904, 0.419814, 0.088461, -0.296028, -0.147114, -0.268263, -0.228123, -0.150374, 0.201236, 0.348198, -0.148170, 0.209257, -0.050047, -0.251723, -0.353571},\n",
      "  {-0.016201, -0.222216, -0.026947, 0.153462, 0.087263, -0.038228, -0.113705, 0.174236, -0.137090, 0.258993, 0.386401, 0.066084, 0.043417, -0.434713, -0.095025, 0.057890, -0.465337, 0.010442, 0.171912, 0.166319, 0.254083, 0.314674, -0.082690, -0.192156}\n",
      "};\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(weights_input_hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float bias_hidden[hidden_neurons][] = {0.031231, -0.027017, 0.049704, 0.040150, 0.203045, 0.087532, -0.030820, -0.028656, 0.005495, 0.045370, 0.057334, 0.059571, -0.048999, 0.150514, 0.109576, 0.115036, 0.040941, -0.012301, 0.023810, 0.000000, 0.130181, -0.022749, -0.029700, 0.183847};\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bias_hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float weights_hidden_output[hidden_neurons][output_neurons][][] = {\n",
      "  {-0.101333, 0.653113, -0.637396, 0.252445, -0.252112},\n",
      "  {-0.394671, -0.092547, -0.262618, -0.272298, 0.053588},\n",
      "  {0.477355, -0.411731, 0.122848, -0.593918, -0.548419},\n",
      "  {-0.512324, -0.405880, 0.492001, -0.121137, 0.391467},\n",
      "  {-0.386964, -0.004100, 0.215261, 0.504756, -0.594486},\n",
      "  {0.449204, -0.304204, 0.661429, -0.166398, 0.549122},\n",
      "  {0.352714, 0.036202, -0.207662, 0.062919, -0.094521},\n",
      "  {-0.193411, -0.130984, 0.250864, 0.085196, 0.227939},\n",
      "  {-0.430924, -0.647486, 0.176277, 0.192143, 0.663633},\n",
      "  {0.316329, 0.612244, -0.241744, -0.387752, -0.212096},\n",
      "  {-0.250297, 0.121468, 0.444805, -0.130483, -0.466932},\n",
      "  {-0.280434, 0.414775, -0.140977, -0.518830, 0.333150},\n",
      "  {0.344138, -0.092053, -0.342019, -0.303110, 0.291451},\n",
      "  {0.686681, -0.708672, -0.943634, 0.087158, 0.713947},\n",
      "  {0.633189, -0.362585, -0.113536, -0.109017, 0.471236},\n",
      "  {-0.554185, 0.295963, -0.548109, -0.783968, 0.514526},\n",
      "  {0.390676, 0.145785, -0.681591, 0.416827, 0.064556},\n",
      "  {0.122097, 0.418087, -0.191008, 0.108331, -0.291868},\n",
      "  {0.246848, -0.103056, 0.119059, -0.852744, -0.311640},\n",
      "  {-0.363532, 0.417679, -0.258529, 0.246219, -0.121425},\n",
      "  {-0.728268, 0.648022, -0.081948, 0.058904, 0.352800},\n",
      "  {-0.154611, 0.311671, -0.422306, -0.083775, -0.089298},\n",
      "  {-0.421484, 0.346782, -0.123498, -0.386681, -0.104241},\n",
      "  {0.101625, -0.336676, 0.170494, 0.537587, -0.473910}\n",
      "};\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(weights_hidden_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float bias_output[output_neurons][] = {-0.124185, -0.058657, 0.011544, 0.135850, -0.030759};\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_bias_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
